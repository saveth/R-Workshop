---
title: "Data Wrangling Part 2:"
subtitle: "Undertanding Your Data"
author: "Savet Hong"
date: "`r format(Sys.Date(), '%b %d, %Y')`"
output:
  slidy_presentation:
      incremental: true
---
  
```{r examples, include=FALSE}
library(readxl)
library(tidyverse)
filing <- read_excel("../data/MockData.xlsx", sheet = "CourtA-Filing", skip = 1)
bail <- read_excel("../data/MockData.xlsx", sheet = "Bail", na = "NA")
```

# Validation

## Scenario: Court Filing Data

- Examine your data
    + Look at the Excel file for the CourtA-Filing
    + Look at the data table in R
-     
    ```{r filing, echo=TRUE, eval=FALSE}
library(readxl)
library(tidyverse)    

filing <- read_excel("../data/MockData.xlsx", sheet = "CourtA-Filing", skip = 1)
```

- What should you be checking when validating a dataset?
    + structure of dataset
    + number of columns/rows
    + calculations built into the document
    + inspect distribution in the data (outliers?)

## 
- Clean up the data
    + Remove the hidden column(s)
    + Calculate the Fiscal Year total. How does it compare to the total in the Excel file?
-     
    ```{r filing_clean, echo=TRUE, eval=FALSE}
filing_clean <- filing %>%
      select(- Total) %>%
      rename( Excel_total = X__1) %>%
      mutate(total = rowSums(.[grep("-", names(.))]),
             total_diff = total - Excel_total)
    
View(filing_clean)    
```


## Scenario: Bail

- Read in the Bail Data
- 
    ```{r bail, echo=TRUE, eval=FALSE}

bail <- read_excel("../data/MockData.xlsx", sheet = "Bail", na = "NA")
```

- Are there any duplicate records in the data?
- Commands to help identify uniqueness of dataset/variables.
    + unique()
    + duplicated()
    + distinct() [requires dplyr]

## 
- Identify how many observations in the data is unique across all variables.
- How many observations are unique based on:
    + Statute code only
    + Statute code and fine amount
    + Fine amount and Description
- How many duplicate records exist in the data?

## 

```{r bail_dup, echo = TRUE, eval=FALSE}
# Unique records
    nrow(bail)
    nrow(unique(bail))

# Unique based on statue only
    bail_statute_only <- bail[!duplicated(bail$Statute),]
    str(bail_statute_only)

# Unique based on code and fine
    bail_unique_stat_fine <- bail %>%
      distinct(Statute, `Base Fine`, .keep_all = TRUE)
    str(bail_unique_stat_fine)

# Unique based on fine and description
    bail_unique_fine_desc <- bail %>%
      distinct(`Offense Description`,`Base Fine`, .keep_all = TRUE)
    str(bail_unique_fine_desc)

# Explain why bail_unique_fine_desc < bail_unique_stat_fine.
    
# Records duplicated Count
    bail_dup_count <- bail %>%
      group_by(Statute, `Base Fine`, `Offense Description`) %>%
      summarise(count = n())
    table(bail_dup_count$count)
```


## Scenario: Peremptory

- Examine the Original Peremptory Data in Excel Workbook
    + What do you observe?
    + Try importing it into R, how did you read it in?

- 
    ```{r, echo = TRUE}
peremp_orig <- read_excel("../data/MockData.xlsx", sheet = "Peremptory_original")
View(peremp_orig)   

peremp_orig2 <- read_excel("../data/MockData.xlsx", sheet = "Peremptory_original", skip = 12, col_names = FALSE)  
View(peremp_orig2) 
```        

- What do you observe?
    
## Scenario: Peremptory Modifiied

- Examine the modified peremptory data
    + What do you observe?
    + Try importing it into R.
-     
    ```{r peremptory, echo=TRUE, eval=FALSE}

peremp_mod <- read_excel("../data/MockData.xlsx", sheet = "Peremptory_modified", skip = 12, col_names = FALSE)
View(peremp_mod)    
```

- How do you clean up the file in R?
    + remove blank columns
    + rename variables
    + remove non-case rows

## 
```{r clean_peremptory, echo= TRUE, eval=FALSE}
peremp_clean <- peremp_mod %>%
      select(- c(X__2, X__4,X__5, X__12:X__20)) %>%
      rename(caseid = X__1, case_title = X__3, retry = X__6, Room = X__7,
             start_date = X__8, end_date = X__9, juror_sent = X__10, 
             disposition = X__11, judge = X__21) %>%
      filter(!is.na(caseid)) %>%
      filter(caseid != "Case ID")
      
```

- Are there additional cleaning or modification that needs to be done?

##
- The accounting office tracks has a system that tracks your unit expenses, and your unit admin also tracks the expenses for your unit. Reconcile the the expenditure.

- What do you examine in the data?
    + same number of records in both data files
    + sum is equivalent
    + same values in both data files
    + if discrepencies exist, validate using third data source


## Practice 1
- Read in the OBJ.RDS data file
    + Extract the first object in the list and save it to an object
    + Extract the second object in the list and save it to a different object

- Perform your data validation
- Assume you validate using a third data source, make the necessary correction.

## Scenario 2
- You have been asked append a manually dataset to the master dataset for a court. The manual data was provided to you in an excel file. What checks do you perform?
  
- Checks
    + number of rows and column correspond to the excel file 
    + if hidden rows/columns exit determine
    + Identify if any columns/rows will be impacted by hidden fields

## Practice 2

- Read in the excel file "filings.xlsx"
- Perform your data checks
- Clean the manual data


## Concepts Covered
1. Validation (vectors and  Data import)
2. Checking for NULL or NA
3. Replacing Data Element (Indexing)
4. Introducing Dplyr


## Exercises

- Read in the OBJ.RDS data file
    + Extract the first object in the list and save it to an object
    + Extract the second object in the list and save it to a different object
    + What are now the different types of data objects that exist in your Evironment?
  
- Imagine the first object came from one data source and the second data object came from a second data source, how would you go about validating the data?
    + Did the two data source collect the same information?
    + Are there any discrepancies?
  
- If the first data source is considered the most valid data, modify and update the second data source if any discrepancies exist.


