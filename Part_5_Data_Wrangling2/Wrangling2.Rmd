---
title: "Data Wrangling Part 2:"
subtitle: "Undertanding Your Data"
author: "Savet Hong"
date: "`r format(Sys.Date(), '%b %d, %Y')`"
output:
  slidy_presentation:
      incremental: true
---
  
```{r examples, include=FALSE}
library(readxl)
library(tidyverse)
filing <- read_excel("../data/MockData.xlsx", sheet = "CourtA-Filing", skip = 1)
bail <- read_excel("../data/MockData.xlsx", sheet = "Bail", na = "NA")
peremp_orig <- read_excel("../data/MockData.xlsx", sheet = "Peremptory_original")
peremp_orig2 <- read_excel("../data/MockData.xlsx", sheet = "Peremptory_original", skip = 12, col_names = FALSE) 
peremp_mod <- read_excel("../data/MockData.xlsx", sheet = "Peremptory_modified", skip = 12, col_names = FALSE)
template <-  read_excel("../data/MockData.xlsx", sheet = "Template")  
```

# Validation

## Scenario: Court Filing Data

- Examine your data
    + Look at the Excel file for the CourtA-Filing
    + Look at the data table in R
-     
    ```{r filing, echo=TRUE, eval=FALSE}
library(readxl)
library(tidyverse)    

filing <- read_excel("../data/MockData.xlsx", sheet = "CourtA-Filing", skip = 1)
```

- What should you be checking when validating a dataset?
    + structure of dataset
    + number of columns/rows
    + calculations built into the document
    + inspect distribution in the data (outliers?)

## 
- Clean up the data
    + Remove the hidden column(s)
    + Calculate the Fiscal Year total. How does it compare to the total in the Excel file?
-
    ```{r filing_clean2, echo=TRUE, eval=FALSE}
# Create a vector to indicate wanted columns
filing_months <- names(filing)
filing_months <- filing_months[ -c(1, 11, 15)]

## Create a clean dataset    

filing_clean <- filing[, -11] # remove total column
names(filing_clean)[names(filing_clean) == 'X__1']  <- 'Excel_total' # change col name

filing_clean$total <- apply(filing_clean[,filing_months], 1, sum) # calc row totals for all months
        # Note: apply() can be used to calculate either row total or column total

filing_clean$total_diff  <- filing_clean$total - filing_clean$Excel_total # add column
    
View(filing_clean)    
```
- 
    ```{r filing_clean1, echo=TRUE, eval=FALSE}
## Create a clean dataset 
filing_clean <- filing %>%
      select(- Total) %>%
      rename( Excel_total = X__1) %>%
      mutate(total = rowSums(.[2:13]),
             total_diff = total - Excel_total)
    
View(filing_clean)    
```


    ```{r filing_clean, echo=TRUE, eval=FALSE, include= FALSE}
# The grep function is too complicated at this time    
filing_clean <- filing %>%
      select(- Total) %>%
      rename( Excel_total = X__1) %>%
      mutate(total = rowSums(.[grep("-", names(.))]),
             total_diff = total - Excel_total)
    
View(filing_clean)    
```


## Scenario: Bail

- Read in the Bail Data
- 
    ```{r bail, echo=TRUE, eval=FALSE}

bail <- read_excel("../data/MockData.xlsx", sheet = "Bail", na = "NA")
```

- Are there any duplicate records in the data?
- Commands to help identify uniqueness of dataset/variables.
    + unique()
    + duplicated()
    + distinct() [requires dplyr]

## 
- Identify how many observations in the data is unique across all variables.
- How many observations are unique based on:
    + Statute code only
    + Statute code and fine amount
    + Fine amount and Description
- How many/ which record have duplicates in the data?

## 
- Unique records
    ```{r bail_dup, echo = TRUE, eval=FALSE}
    nrow(bail)
    nrow(unique(bail))
```

- Unique based on statue only
    ```{r ,echo=TRUE, eval=FALSE} 
    bail_statute_only <- bail[!duplicated(bail$Statute),]
    str(bail_statute_only)
```

- Unique based on code and fine
    ```{r ,echo=TRUE, eval=FALSE} 
    bail_unique_stat_fine <- bail %>%
      distinct(Statute, `Base Fine`, .keep_all = TRUE)
    str(bail_unique_stat_fine)
```
    
- Unique based on fine and description
    ```{r ,echo=TRUE, eval=FALSE} 
    bail_unique_fine_desc <- bail %>%
      distinct(`Offense Description`,`Base Fine`, .keep_all = TRUE)
    str(bail_unique_fine_desc)
```

- Explain why bail_unique_fine_desc < bail_unique_stat_fine.
    
- Records duplicated Count
    ```{r ,echo=TRUE, eval=FALSE} 
    bail_dup_count <- bail %>%
      group_by(Statute, `Base Fine`, `Offense Description`) %>%
      summarise(count = n())
    table(bail_dup_count$count)
```


## Scenario: Peremptory

- Examine the Original Peremptory Data in Excel Workbook
    + What do you observe?
    + Try importing it into R, how did you read it in?

- 
    ```{r, echo = TRUE, eval=FALSE}
peremp_orig <- read_excel("../data/MockData.xlsx", sheet = "Peremptory_original")
View(peremp_orig)   

peremp_orig2 <- read_excel("../data/MockData.xlsx", sheet = "Peremptory_original", skip = 12, col_names = FALSE)  
View(peremp_orig2) 
```        

- What do you observe?

##
- Notice that the original data contains element for each case as part of the header
- Difficult to parse out or include specific data element in batch for group of cases
- The excel sheet requires a little more structure to help resolve the issue of cleaning in R
    
## Scenario: Peremptory Modifiied

- Examine the modified peremptory data
    + What do you observe?
    + Try importing it into R.
-     
    ```{r peremptory, echo=TRUE, eval=FALSE}

peremp_mod <- read_excel("../data/MockData.xlsx", sheet = "Peremptory_modified", skip = 12, col_names = FALSE)
View(peremp_mod)    
```

- How do you clean up the file in R?
    + remove blank columns
    + rename variables
    + remove non-case rows

## 
- check for columns with all NAs
    ```{r peremptory_nas, echo= TRUE, eval=FALSE}
sapply(peremp_mod, function(x) all(is.na(x))) 
```

- Clean up the imported data file
    ```{r clean_peremptory, echo= TRUE, eval=FALSE}  

peremp_clean <- peremp_mod %>%
      select(- c(X__4,X__5, X__12:X__20)) %>%
      rename(caseid = X__1, case_title = X__3, retry = X__6, Room = X__7,
             start_date = X__8, end_date = X__9, juror_sent = X__10, 
             disposition = X__11, judge = X__21) %>%
      filter(!is.na(caseid)) %>%
      filter(caseid != "Case ID")
      
```

- Are there additional cleaning or modification that needs to be done?


## Scenario: Template to Data Tables
- Examine the template data
    + What do you observe?
    + Can the data be imported as is and cleaned in R? 
    + Or does it require modification in the Excel file first? 

- What steps needs to be done to clean the data once it's loaded into R?
    + remove blank/irrelevant columns (bullet cells)
    + rename columns
    + add "total" where needed
    + Expand the categories in column A
        - Indentify the unique elements
        - Position between each unique elements
        - Create a vector with the unique vector expanded equal to the distance between elements
        - Repopulate or create a new column with the new vector
    + Remove rows with none relevant data records   

## Concepts Covered
1. Validation (Original Data and  Data import)
2. Checking for NULL or NA
3. Replacing Data Element (Indexing)
4. Identify/Manage Duplicate Records
5. Creating a Clean Flat Data File in R from a non-standardized Excel data file


## Exercises
### CourtA-Filing Data
1. Validate the Column total for each month
2. Transform you clean filing data into a long dataset
    + HINT: it should have three columns: casetype, fiscal_month, filing

### Template Data
3. Please read in the Template data and perform the necessary data cleaning.
    + HINT: useful functions: unique(),is.na(), which(), diff()

